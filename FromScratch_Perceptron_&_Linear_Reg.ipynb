{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FromScratch_Perceptron_&_Linear_Reg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sopkart/ai-workshop-summer-2022/blob/main/FromScratch_Perceptron_%26_Linear_Reg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9sGoCULjcOc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def readDataFile(fileName):\n",
        "  return pd.read_csv(fileName, names=['x1', 'x2', 'x3', 'x4', 'y'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def splitData(data, t_size):\n",
        "  return train_test_split(data, test_size=t_size, random_state=50)\n"
      ],
      "metadata": {
        "id": "RfZ2qFxflqDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_X_Y(data):\n",
        "  return data.loc[:,'x1':'x4'].values, data.loc[:, 'y'].values"
      ],
      "metadata": {
        "id": "Uv8OJEb8mk03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "x = [x1 x2 x3 x4]\n",
        "w = [w1 w2 w3 w4]\n",
        "b = c\n",
        "\n",
        "Ex: for single column_or_1d\n",
        "    x = [a]\n",
        "    w = [b]\n",
        "    b = c\n",
        "\n",
        "    w * b = ab\n",
        "    y = w * x + b // simple mathematical operation\n",
        "\n",
        "For multiple columns of x, where no of columns > 1\n",
        "  x = [x1 x2 x3 x4]\n",
        "  w = [w1 w2 w3 w4]\n",
        "  b = c\n",
        "\n",
        "  x and w are vectors\n",
        "   x * w = (x1.w1 + x2.w2 + x3.w3 + x4.w4)\n",
        "\n",
        "  Since x and w are represent as row matrix(if any doubt, google about 'row matrix')\n",
        "    we have to take\n",
        "      xT * w\n",
        "\n",
        "'''\n",
        "# h(x)\n",
        "def _hypo(X, w, b):\n",
        "  return np.dot(X, w) + b\n",
        "\n",
        "# loss(x)\n",
        "def _loss(X, Y, w, b):\n",
        "  loss = (-Y * _hypo(X, w, b))\n",
        "  loss[loss >= 0] = 1\n",
        "  loss[loss < 0] = 0\n",
        "  return loss\n",
        "\n",
        "''' intial w, b\n",
        "      w(t+1) = w(t) - stepSize * delta_w(t)\n",
        "      b(t+1) = b(t) - stepSize * delta_b(t)\n",
        "   until min is found or loss == 0\n",
        "'''\n",
        "#gradient_descent()\n",
        "def gradientDescent(X, Y, w0, b0, stepSize):\n",
        "  #intial w0, b0\n",
        "  w_t = w0\n",
        "  b_t = b0\n",
        "  it = 1\n",
        "\n",
        "  loss = _loss(X, Y, w_t, b_t)\n",
        "  no_of_misc = sum(loss)\n",
        "  while (no_of_misc != 0):\n",
        "\n",
        "    delta_b = Y * loss\n",
        "    delta_w = np.sum(delta_b[:, np.newaxis] * X, axis=0)\n",
        "\n",
        "    w_t += stepSize * delta_w\n",
        "    b_t += stepSize * sum(delta_b)\n",
        "\n",
        "    loss = _loss(X, Y, w_t, b_t)\n",
        "    no_of_misc = sum(_loss(X, Y, w_t, b_t))\n",
        "\n",
        "    it +=1 \n",
        "  return w_t, b_t, it\n"
      ],
      "metadata": {
        "id": "5sae52eAp7-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = readDataFile('perceptron.data')\n",
        "tr_data, tst_data = splitData(data, 0.05)\n",
        "\n",
        "X, Y = get_X_Y(tr_data)\n",
        "\n",
        "w, b, it = gradientDescent(X, Y, [1, 1, 1, 1], 1, 0.1)\n",
        "\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "print(\"No of iteration: \", it)\n",
        "\n",
        "Xt, Yt = get_X_Y(tst_data)\n",
        "ls = _loss(Xt, Yt, w, b)\n",
        "print(\"Accurancy :\", 1 - (sum(ls)/ls.shape[0]))"
      ],
      "metadata": {
        "id": "61SuVZrDpTe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7627f9-0f9d-4bac-de27-162532525fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 44.33989613  15.10542273   0.17524539 -50.88189332]\n",
            "-97.00000000000001\n",
            "No of iteration:  36\n",
            "Accurancy : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w, b, it = gradientDescent(X, Y, [0, 0, 0, 0], 0, 0.1)\n",
        "\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "print(\"No of iteration: \", it)\n",
        "Xt, Yt = get_X_Y(tst_data)\n",
        "ls = _loss(Xt, Yt, w, b)\n",
        "print(\"Accurancy :\", 1 - (sum(ls)/ls.shape[0]))"
      ],
      "metadata": {
        "id": "oSuVlVULgA6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63d6c9d-ba3d-4ec7-f61d-edb6386c74dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 64.97172593  22.67096543   0.75327918 -75.49946545]\n",
            "-142.10000000000005\n",
            "No of iteration:  30\n",
            "Accurancy : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w, b, it = gradientDescent(X, Y, [0, 0, 0, 0], 0, 1)\n",
        "\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "print(\"No of iteration: \", it)\n",
        "\n",
        "\n",
        "Xt, Yt = get_X_Y(tst_data)\n",
        "ls = _loss(Xt, Yt, w, b)\n",
        "print(\"Accurancy :\", 1 - (sum(ls)/ls.shape[0]))"
      ],
      "metadata": {
        "id": "ti6642xlgInB",
        "outputId": "1b29b910-e060-4f28-8412-6b2164d19dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 649.71725933  226.70965427    7.53279184 -754.99465449]\n",
            "-1421.0\n",
            "No of iteration:  30\n",
            "Accurancy : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# h(x)\n",
        "def _hypo(X, w, b):\n",
        "  return np.dot(X, w) + b\n",
        "\n",
        "# loss(x)\n",
        "def _loss(X, Y, w, b):\n",
        "  return np.sum(((_hypo(X, w, b) - Y) ** 2)/ (2 * X.shape[0]))\n",
        "\n",
        "''' intial w, b\n",
        "      w(t+1) = w(t) - stepSize * delta_w(t)\n",
        "      b(t+1) = b(t) - stepSize * delta_b(t)\n",
        "   until convergence or gradient is very small\n",
        "'''\n",
        "#gradient_descent()\n",
        "def gradientDescent(X, Y, w0, b0, stepSize):\n",
        "  m = X.shape[0]\n",
        "  w_t = w0\n",
        "  b_t = b0\n",
        "  it = 1\n",
        "\n",
        "  while (it < 10000):\n",
        "    ploss = _loss(X, Y, w_t, b_t)\n",
        "    \n",
        "    delta_b = np.sum(_hypo(X, w_t, b_t) - Y) / m\n",
        "    delta_w = np.sum(X * (_hypo(X, w_t, b_t) - Y).reshape(-1, 1), axis =0) / m\n",
        "\n",
        "    w_t -= stepSize * delta_w\n",
        "    b_t -= stepSize * delta_b\n",
        "\n",
        "    loss = _loss(X, Y, w_t, b_t)\n",
        "    \n",
        "    if (abs(ploss-loss) < 10**(-9)):\n",
        "      break\n",
        "\n",
        "    it +=1 \n",
        "  return w_t, b_t, it"
      ],
      "metadata": {
        "id": "lWF4YFwUuppo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, linear_model, metrics\n",
        "\n",
        "boston = datasets.load_boston(return_X_y=False)\n",
        "  \n",
        "# defining feature matrix(X) and response vector(y)\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "w_t = np.ones(X.shape[1])\n",
        "b_t = 1\n",
        "\n",
        "\n",
        "#np.dot(X, w) + b\n",
        "\n",
        "w, b, it = gradientDescent(X, y, np.zeros(X.shape[1]), 0, 1)"
      ],
      "metadata": {
        "id": "s01HLLq6iTXf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}